{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copyright (c) Microsoft Corporation.\n",
        "# Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training\n",
        "Train a prediction model that indicites whether a user will click on an article or not, compute performance metrics on dev data, and store the model for recommendation data\n",
        "\n",
        "1. Define variables\n",
        "2. Load the datasets\n",
        "3. Create feature engineering transformer\n",
        "4. Train model\n",
        "5. Test model\n",
        "6. Store model and transformer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyspark\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.feature import FeatureHasher, Word2Vec, Tokenizer,  OneHotEncoderEstimator, StopWordsRemover, VectorAssembler, StringIndexer, HashingTF, IDF\n",
        "\n",
        "from mmlspark.train import ComputeModelStatistics\n",
        "from mmlspark.lightgbm import LightGBMClassifier\n",
        "\n",
        "\n",
        "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import types\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define variables (input folder, datasets, ....)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Setup global variables\n",
        "dataset_train =  'default.activitytrain'\n",
        "dataset_dev = 'default.activitydev'\n",
        "col_user = 'User_ID'\n",
        "col_item = 'Article_ID'\n",
        "col_target = 'Clicked'\n",
        "feature_processor_name = 'feature_proprecssor.mml'\n",
        "model_name = \"news_recommendation_model.mml\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Train and Dev Datasets\n",
        "\n",
        "The training dataset set is used to train the model and the dev dataset is used to assess the performance of the model on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Read dataset\n",
        "df_train  = spark.read.table(dataset_train)\n",
        "df_dev  = spark.read.table(dataset_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Here, the code applies different transformations depending on the column and type of data it contains:\n",
        "\n",
        "- _Category/SubCategory_: convert text to integer. For instance, Word A becomes 1 and Word B becomes 2\n",
        "\n",
        "- _Title/Abstract_:  first, sentences are tokenised into a list of words. For instance, \"first day of week\" becomes \\[first, day, of, week]. Then stop words (a, the, of, etc) are removed, then only the most relevant words are kept using TF/IDF transformation\n",
        "\n",
        "- _History_: each user has a different history of viewed articles. Here again TF/IDF is applied to keep only the most relevant articles. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "# convert strings to integers\n",
        "strindexer1 = StringIndexer(inputCol=\"Category\", outputCol=\"Category_Idx\", handleInvalid='keep')\n",
        "strindexer2 = StringIndexer(inputCol=\"SubCategory\", outputCol=\"SubCategory_Idx\", handleInvalid='keep')\n",
        "\n",
        "# Process and filter title and abstract information\n",
        "tokenizer_title = Tokenizer(inputCol=\"Title\", outputCol=\"Title_tokens\")\n",
        "StopWordsRemover_title = StopWordsRemover(inputCol=tokenizer_title.getOutputCol(), outputCol=\"title_filtered\")\n",
        "hashingTF_title = HashingTF(inputCol=StopWordsRemover_title.getOutputCol(), outputCol=\"hashed_title\", numFeatures=10)\n",
        "idf_title = IDF(inputCol=hashingTF_title.getOutputCol(), outputCol=\"features_title\")\n",
        "\n",
        "tokenizer_abstract = Tokenizer(inputCol=\"Abstract\", outputCol=\"Abstract_tokens\")\n",
        "StopWordsRemover_abstract= StopWordsRemover(inputCol=tokenizer_title.getOutputCol(), outputCol=\"abstract_filtered\")\n",
        "hashingTF_abstract = HashingTF(inputCol=StopWordsRemover_abstract.getOutputCol(), outputCol=\"hashed_abstract\", numFeatures=10)\n",
        "idf_abstract = IDF(inputCol=hashingTF_abstract.getOutputCol(), outputCol=\"features_abstract\")\n",
        "\n",
        "# Apply tf-idf on viewed articles\n",
        "hashingTF_history = HashingTF(inputCol='History', outputCol=\"hashed_history\", numFeatures=100)\n",
        "idf_history = IDF(inputCol=hashingTF_history.getOutputCol(), outputCol=\"feature_history\")\n",
        "\n",
        "# Assemble the output of each transformer into a single of lists\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        strindexer1.getOutputCol(),\n",
        "        strindexer2.getOutputCol(),\n",
        "        idf_title.getOutputCol(),\n",
        "        idf_abstract.getOutputCol(),\n",
        "        idf_history.getOutputCol(),\n",
        "        ], \n",
        "        outputCol=\"features\"\n",
        "        )\n",
        "\n",
        "# Create the whole feature processor\n",
        "feature_processor = Pipeline(\n",
        "    stages=[\n",
        "        strindexer1,\n",
        "        strindexer2,\n",
        "        tokenizer_title,\n",
        "        StopWordsRemover_title,\n",
        "        hashingTF_title,\n",
        "        idf_title,\n",
        "        tokenizer_abstract,\n",
        "        StopWordsRemover_abstract,\n",
        "        hashingTF_abstract,\n",
        "        idf_abstract,\n",
        "        hashingTF_history,\n",
        "        idf_history,\n",
        "        assembler       \n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Fit the feature transformers\n",
        "fitted_processor = feature_processor.fit(df_train)\n",
        "df_train_feature = fitted_processor.transform(df_train)\n",
        "df_dev_feature = fitted_processor.transform(df_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define and Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "#Instantiate model\n",
        "\n",
        "# Setup Hyperparameters\n",
        "NUM_LEAVES = 32\n",
        "NUM_ITERATIONS = 50\n",
        "LEARNING_RATE = 0.1\n",
        "FEATURE_FRACTION = 0.8\n",
        "EARLY_STOPPING_ROUND = 10\n",
        "\n",
        "lgbm = LightGBMClassifier(\n",
        "    labelCol=col_target,\n",
        "    featuresCol=\"features\",\n",
        "    probabilityCol='probability', \n",
        "    objective=\"binary\",\n",
        "    isUnbalance=True,\n",
        "    boostingType=\"gbdt\",\n",
        "    boostFromAverage=True,\n",
        "    baggingSeed=42,\n",
        "    numLeaves=NUM_LEAVES,\n",
        "    numIterations=NUM_ITERATIONS,\n",
        "    learningRate=LEARNING_RATE,\n",
        "    featureFraction=FEATURE_FRACTION,\n",
        "    earlyStoppingRound=EARLY_STOPPING_ROUND\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# train model\n",
        "model = lgbm.fit(df_train_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the model on dev dataset\n",
        "\n",
        "The metrics used to assess model performances are Precision, Recall, F1, and Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "def evaluate_model(model,df_test):\n",
        "    predictions = model.transform(df_test)\n",
        "\n",
        "    #drops nan in prediction\n",
        "    predictions = predictions.dropna()\n",
        "\n",
        "    #convert prediction probability\n",
        "    predictions = predictions.withColumn('prediction', F.round('prediction').cast(types.DoubleType()))\n",
        "    evaluatorMulti = MulticlassClassificationEvaluator(labelCol=col_target, predictionCol=\"prediction\")\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=col_target, rawPredictionCol=\"prediction\")\n",
        "\n",
        "    f1 = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"f1\"})\n",
        "    weightedPrecision = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
        "    weightedRecall = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
        "\n",
        "    auc = evaluator.evaluate(predictions)\n",
        "    return f1, weightedPrecision, weightedRecall, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# print accuracy, F1 score, precision and recall\n",
        "f1, weightedPrecision, weightedRecall, auc = evaluate_model(model,df_dev_feature)\n",
        "print('DEV AUC:', auc)\n",
        "print('DEV F1:', f1)\n",
        "print('DEV Precision:', weightedPrecision, 'DEV Recall:',weightedRecall)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Store fitted feature processor and model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# store model\n",
        "fitted_processor.write().overwrite().save(feature_processor_name)\n",
        "model.write().overwrite().save(model_name)\n"
      ]
    }
  ]
}